{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 分布式数据并行\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    PyTorch_DDP[\"PyTorch 分布式数据并行（DDP）\"]\n",
    "    DDP_Overview[\"DDP 实现分布式训练的概述\"]\n",
    "    NonDistributed_vs_Distributed[\"非分布式训练与分布式对比\"]\n",
    "    NonDistributed_Training[\"非分布式训练\"]\n",
    "    Single_GPU[\"单个 GPU 上有一个模型\"]\n",
    "    Compute_Loss[\"接收输入计算损失并更新模型\"]\n",
    "    Distributed_Training[\"分布式训练\"]\n",
    "    Local_Model[\"每个 GPU 一个进程有本地模型\"]\n",
    "    Distributed_Sampler[\"使用分布式采样器获取不同输入\"]\n",
    "    Synchronization[\"同步步骤\"]\n",
    "    Prevent_Divergence[\"防止出现不同模型进行同步\"]\n",
    "    Bucket_Reduction[\"采用桶式环归约算法聚合梯度\"]\n",
    "    Algorithm_Advantages[\"算法优势\"]\n",
    "    Gradient_Communication[\"梯度计算与通信重叠\"]\n",
    "    GPU_Utilization[\"确保 GPU 始终工作不空闲\"]\n",
    "    Training_Results[\"训练结果\"]\n",
    "    Parameter_Sync[\"所有模型副本参数同步更新\"]\n",
    "    Next_Iteration[\"相同副本为下一次迭代准备\"]\n",
    "\n",
    "    PyTorch_DDP --> DDP_Overview\n",
    "    PyTorch_DDP --> NonDistributed_vs_Distributed\n",
    "    NonDistributed_vs_Distributed --> NonDistributed_Training\n",
    "    NonDistributed_Training --> Single_GPU\n",
    "    NonDistributed_Training --> Compute_Loss\n",
    "    NonDistributed_vs_Distributed --> Distributed_Training\n",
    "    Distributed_Training --> Local_Model\n",
    "    Distributed_Training --> Distributed_Sampler\n",
    "    PyTorch_DDP --> Synchronization\n",
    "    Synchronization --> Prevent_Divergence\n",
    "    Synchronization --> Bucket_Reduction\n",
    "    PyTorch_DDP --> Algorithm_Advantages\n",
    "    Algorithm_Advantages --> Gradient_Communication\n",
    "    Algorithm_Advantages --> GPU_Utilization\n",
    "    PyTorch_DDP --> Training_Results\n",
    "    Training_Results --> Parameter_Sync\n",
    "    Training_Results --> Next_Iteration\n",
    "```\n",
    "## 01 DDP 实现分布式训练的概述 \n",
    "DDP 是 PyTorch 中用于实现分布式训练的模块。它允许用户在多个 GPU 或多个机器上并行训练模型，从而加速训练过程并提高资源利用率。\n",
    "\n",
    "## 02 DP 与 DDP 对比\n",
    "DataParallel 是单进程多线程，只能在单台机器上运行，而 DDP 是多进程，支持单台和多台机器训练。DDP 在处理大规模模型时通常比 DataParallel 更快，且能与模型并行结合，而 DataParallel 目前不能。\n",
    "\n",
    "## 02 非分布式训练与分布式对比\n",
    "非分布式训练：在单个 GPU 上训练模型，每个 GPU 上只有一个模型副本。训练过程是顺序进行的，每个 GPU 计算损失并更新模型。\n",
    "\n",
    "分布式训练：在多个 GPU 或多个机器上训练模型，每个 GPU 或机器上都有一个模型副本。训练过程是并行进行的，多个 GPU 或机器同时计算损失并更新模型。\n",
    "\n",
    "## 03 同步步骤\n",
    "\n",
    "### DDP 的数据处理\n",
    "使用分布式采样器获取不同输入，确保每个 GPU 或机器处理不同的数据批次。\n",
    "\n",
    "### 梯度计算\n",
    "因为不同的数据批次可能包含不同的数据，所以每个 GPU 或机器计算出的梯度可能不同。为了防止出现不同模型进行同步，DDP 采用环归约算法聚合梯度（Ring Allreduce）。\n",
    "\n",
    "--- \n",
    "#### Ring-AllReduce 算法\n",
    "Ring-AllReduce算法是一种用于分布式计算环境中高效实现全规约（AllReduce）操作的算法，常用于多GPU或多节点的深度学习训练场景，能显著提升计算效率。其核心原理基于环形拓扑结构进行数据的交换和规约，具体如下：\n",
    "1. **环形拓扑结构**：在Ring-AllReduce算法中，所有参与计算的节点（如GPU）被组织成一个逻辑环。每个节点仅与相邻的两个节点进行直接通信，这减少了整体的通信复杂度和网络拥塞 。例如，在一个包含4个GPU的系统中，GPU 1与GPU 2、GPU 4相连，GPU 2与GPU 1、GPU 3相连，以此类推形成环形结构。\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    GPU1[\"GPU 1\"]\n",
    "    GPU2[\"GPU 2\"]\n",
    "    GPU3[\"GPU 3\"]\n",
    "    GPU4[\"GPU 4\"]\n",
    "    GPU1 --> GPU2\n",
    "    GPU2 --> GPU3\n",
    "    GPU3 --> GPU4\n",
    "    GPU4 --> GPU1\n",
    "```\n",
    "\n",
    "2. **数据划分与分发**：在进行规约操作前，每个节点会将其本地数据划分为多个片段（chunk）。假设每个节点都有数据片段，为了进行规约，会将该张量按维度或其他方式分割成多个较小的部分。然后，节点将自己的部分数据发送给环中的下一个节点，同时从环中的上一个节点接收其他节点的数据片段。\n",
    "3. **规约与传播**：每个节点在接收到相邻节点的数据片段后，会将接收到的数据与自身对应的数据片段进行规约操作。常见的规约操作包括求和（sum）、求平均（average）等。在完成规约后，节点会将结果发送给环中的下一个节点。这个过程会在环中持续进行，直到每个节点都接收到所有其他节点的数据片段并完成规约，最终每个节点都拥有所有数据规约后的完整结果。\n",
    "4. **流水线操作**：为了进一步提高效率，Ring-AllReduce通常采用流水线操作方式。在数据的发送、接收和规约过程中，各个阶段可以重叠进行。例如，当一个节点正在接收数据片段时，它可以同时对之前接收到的数据片段进行规约操作，并且准备将规约后的结果发送给下一个节点。这种流水线操作减少了整体的等待时间，提高了算法的执行效率。\n",
    "\n",
    "5. **多轮迭代（可选）**：在处理大规模数据或复杂计算时，可能需要进行多轮的Ring-AllReduce操作。每一轮操作会逐步合并和规约数据，最终得到全局的规约结果。在深度学习训练中，通常会在每次反向传播计算梯度后，使用Ring-AllReduce算法来聚合各个GPU上计算得到的梯度，以便更新模型参数。\n",
    "\n",
    "Ring-AllReduce算法通过环形拓扑结构和流水线操作，有效降低了通信开销和计算等待时间，提高了分布式计算环境中全规约操作的效率，成为深度学习分布式训练中常用的通信算法之一。 \n",
    "\n",
    "---\n",
    "\n",
    "在一次迭代中，当所有的GPU 都完成了梯度计算后，它们会通过环归约算法聚合梯度，然后更新模型参数。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
